{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import operator\n",
    "import csv\n",
    "from os import path\n",
    "from copy import copy\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traces = [\n",
    "    ('T1' , '/home/tiratatp/Repositories/snia_traces/T1/LiveMapsBackEnd/Combined/disk1_filtered_1hrs.txt'),\n",
    "    ('T2' , '/home/tiratatp/Repositories/snia_traces/T2/DisplayAdsDataServer/Combined/disk0_1hrs.txt'),\n",
    "    ('T3' , '/home/tiratatp/Repositories/snia_traces/T3/DisplayAdsPayload/Combined/disk0_1hrs.txt'),\n",
    "    ('T4' , '/home/tiratatp/Repositories/snia_traces/T4/Exchange-Server-Traces/Combined/disk8_1hrs.txt'),\n",
    "    ('T5' , '/home/tiratatp/Repositories/snia_traces/T5/MSNStorageCFS/Combined/disk6_filtered_1hrs.txt'),\n",
    "    ('T6' , '/home/tiratatp/Repositories/snia_traces/T6/MSNStorageFileServer/Combined/disk5_filtered_1hrs.txt'),\n",
    "    ('T7' , '/home/tiratatp/Repositories/snia_traces/T7/BuildServer/Combined/disk0_filtered_1hrs.txt'),\n",
    "    ('T8' , '/home/tiratatp/Repositories/snia_traces/T8/DevelopmentToolsRelease/Combined/disk6_filtered_1hrs.txt'),\n",
    "    ('T9' , '/home/tiratatp/Repositories/snia_traces/T9/RadiusAuthentication/Combined/disk0_filtered_1hrs.txt'),\n",
    "    ('T10', '/home/tiratatp/Repositories/snia_traces/T10/RadiusBackEndSQLServer/Combined/disk4_filtered_1hrs.txt'),    \n",
    "]\n",
    "\n",
    "last_block=1953525167\n",
    "\n",
    "#cutoff size in KB\n",
    "policy_size = 32\n",
    "\n",
    "#info about size of preallocated shelters:\n",
    "sheltersize = 10\n",
    "shelterrange = 100\n",
    "\n",
    "# swap shelter if it's full\n",
    "swap = True\n",
    "\n",
    "#cleanup = False\n",
    "cleanup = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from Nora\n",
    "\"\"\"\n",
    "Sheltering Simulator.\n",
    "Writes <= `policy_size` KB are sheltered.\n",
    "\"\"\"\n",
    "#MB in sectors\n",
    "one_MB = 2 * 1024\n",
    "\n",
    "x = sheltersize * one_MB\n",
    "y = shelterrange * one_MB\n",
    "assert x < y\n",
    "\n",
    "#FUNCTIONS\n",
    "def round_down(num, divisor):\n",
    "    return num - (num%divisor)\n",
    "\n",
    "#return 1st block number of next shelter after block_num\n",
    "def get_next_shelter (block_num):\n",
    "    shelter = round_down(block_num, y) + (x * 9)\n",
    "    #If shelter starts before block_num, last write must have been sheltered too\n",
    "    #That's okay--we just want beginning of shelter\n",
    "    return shelter\n",
    "\n",
    "#given a request, break it into a list of requests \n",
    "#none of which overlaps with a shelter\n",
    "def dodge_shelters(req):\n",
    "    start = req[2]\n",
    "    size = req[3]\n",
    "    next_shelter = get_next_shelter(start)\n",
    "    if start + size <= next_shelter:\n",
    "        return [req]\n",
    "    else:\n",
    "        overlap = start + size - next_shelter\n",
    "        new_req = copy(req)\n",
    "        new_req[3] = size - overlap\n",
    "        next_req = copy(req)\n",
    "        next_req[2] = next_shelter + x\n",
    "        next_req[3] = overlap\n",
    "        new_reqs = dodge_shelters(next_req)\n",
    "        new_reqs.append(new_req)\n",
    "        return new_reqs\n",
    "\n",
    "#CLASSES\n",
    "class Shelter:\n",
    "    \"\"\"Keep track of information about shelter,\n",
    "    including how full it is and requests in it that need to be cleaned.\"\"\"\n",
    "    def __init__(self, blk):\n",
    "        self.start = blk\n",
    "        self.tail = blk\n",
    "        self.end = self.start + x\n",
    "        assert(self.end % y == 0)\n",
    "        #a request is of the form (blknum, blksize)\n",
    "        #we only keep track of these if we are cleaning up\n",
    "        self.reqs = []\n",
    "        return\n",
    "    def enough_space(self, reqs):\n",
    "        # we don't really care about this we just want to enable \"cleanup\" to keep track of blocks\n",
    "        #return True\n",
    "        if not(cleanup):\n",
    "            #no cleanup, so doesn't matter\n",
    "            return True\n",
    "        else:\n",
    "            total_size = sum([row[3] for row in reqs])\n",
    "            if total_size <= (self.end - self.tail):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    def shelter_writes(self, current_reqs):\n",
    "        global window\n",
    "        #assert self.enough_space(current_reqs.requests) \n",
    "        if swap:\n",
    "            while not self.enough_space(current_reqs.requests):\n",
    "                # find the least crowded shelter (window size of `window`)\n",
    "                sorted_shelters = sorted(shelters.items(), key=operator.itemgetter(0))\n",
    "                shelter_by_size = map(lambda tup: sum([bcount for _, bcount in tup[1].reqs]), sorted_shelters)\n",
    "                shelter_by_moving_average_size=list(np.convolve(shelter_by_size, np.ones(window)/window, mode='same'))\n",
    "                selected = sorted_shelters[np.argmin(shelter_by_moving_average_size)]\n",
    "\n",
    "                # swap requests\n",
    "                tmp = selected[1].reqs\n",
    "                selected[1].reqs = self.reqs\n",
    "                self.reqs = tmp\n",
    "\n",
    "                # change tails\n",
    "                selected_size = selected[1].tail - selected[1].start\n",
    "                current_size = self.tail - self.start\n",
    "                selected[1].tail = selected[1].start + current_size\n",
    "                self.tail = self.start + selected_size\n",
    "\n",
    "                if not self.enough_space(current_reqs.requests):    \n",
    "                    if window == 1 or np.average(shelter_by_size) >= (x * 0.9):\n",
    "                        raise ValueError(\"Shelters are really full!\")                    \n",
    "                    window /= 2\n",
    "\n",
    "        #if we need to clean up later, consolidate this list of requests,\n",
    "        #which we know are sequential, into one request, remembering\n",
    "        #where it will need to be written later\n",
    "        if cleanup:\n",
    "            cleanup_req_blk = current_reqs.requests[0][2]\n",
    "            cleanup_req_size = 0\n",
    "        for req in current_reqs.requests:\n",
    "            size = req[3]\n",
    "            req[5] = 1 # mark as sheltered\n",
    "            #make sure request isn't larger than whole shelter\n",
    "            if size > x:\n",
    "                print req\n",
    "                print x\n",
    "                sys.exit(0)\n",
    "            if self.tail + size > self.end:\n",
    "                #out of space, back to beginning of buffer\n",
    "                self.tail = self.start\n",
    "            #modify request to write to tail of shelter\n",
    "            req[2] = self.tail\n",
    "            self.tail += size\n",
    "            if cleanup:\n",
    "                cleanup_req_size += size\n",
    "        if cleanup:\n",
    "            self.reqs.append((cleanup_req_blk, cleanup_req_size))\n",
    "        return\n",
    "\n",
    "class CurrentReq:\n",
    "    \"\"\"Keep track of information about current sequential series of writes.\"\"\"\n",
    "    def __init__(self, request):\n",
    "        #total size of current series of requests\n",
    "        self.size = request[3]\n",
    "        #are these reads or writes?\n",
    "        self.flag = request[4]\n",
    "        #we used pandas to calculate this\n",
    "        self._should_shelter = request[5]\n",
    "        #the requests themselves\n",
    "        self.requests = [request]        \n",
    "        return\n",
    "    #the next sequential block in this series\n",
    "    def get_next_blk(self):\n",
    "        #we just look at last block; after shifting, this series may no longer be sequential\n",
    "        return self.requests[-1][2] + self.requests[-1][3]\n",
    "    def should_shelter(self):\n",
    "        return self._should_shelter\n",
    "    def shift_requests(self):\n",
    "        #if our code is B, don't modify requests\n",
    "        #return\n",
    "        # since in our implementation, we don't shift\n",
    "        #if args.code != \"B\":\n",
    "            new_reqs = []\n",
    "            for req in self.requests:\n",
    "                start_blk = req[2]\n",
    "                size = req[3]\n",
    "                #num_shelters is number of shelters that END behind the FIRST \n",
    "                #block of the request\n",
    "                num_shelters = start_blk / y\n",
    "                shift = num_shelters * x\n",
    "                new_start = start_blk + shift\n",
    "                next_shelter = get_next_shelter(new_start)\n",
    "                if new_start >= next_shelter:\n",
    "                    #new_start is inside a shelter, shift it to just after shelter\n",
    "                    #new_start = next_shelter + x\n",
    "                    new_start += x\n",
    "                    next_shelter = get_next_shelter(new_start)\n",
    "                req[2] = new_start\n",
    "                #split up request as needed so it doesn't run into a shelter\n",
    "                split_reqs = dodge_shelters(req)\n",
    "                split_reqs.reverse()\n",
    "                if not split_reqs:\n",
    "                    print \"no split_reqs!\"\n",
    "                new_reqs.extend(split_reqs)\n",
    "            self.requests = new_reqs\n",
    "            return\n",
    "\n",
    "#HERE IS ANOTHER FUNCTION    \n",
    "            \n",
    "#modify requests in request[disk_num] so they're sheltered\n",
    "def shelter_writes (current_requests):\n",
    "    #if tail is negative, there's nothing to shelter behind,\n",
    "    #because this is the first request for this disk\n",
    "    #so don't change it\n",
    "    if tail >= 0:\n",
    "        shelter_blk = get_next_shelter(tail)\n",
    "        if shelter_blk < tail and not(last_sheltered):\n",
    "            #the tail is inside a shelter\n",
    "            #this should only happen if we're in policy B, so not shifting\n",
    "            #in which case we jump to next shelter\n",
    "            #assert (args.code == \"B\")\n",
    "            #if args.code != \"B\":\n",
    "            print \"shelter block: \"+str(shelter_blk)\n",
    "            print \"tail: \"+str(tail)\n",
    "            sys.exit(0)\n",
    "            shelter_blk += y\n",
    "        if shelter_blk not in shelters:\n",
    "            raise ValueError(\"This should not happen! Try increase `shelter_count` (shelter_blk: %d, shelter#: %d)\" % (shelter_blk, (shelter_blk-(x*9))/y,))\n",
    "        shelter = shelters[shelter_blk]\n",
    "        shelter.shelter_writes(current_requests)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 /home/tiratatp/Repositories/snia_traces/T1/LiveMapsBackEnd/Combined/disk1_filtered_1hrs.txt\n",
      "T2 /home/tiratatp/Repositories/snia_traces/T2/DisplayAdsDataServer/Combined/disk0_1hrs.txt\n",
      "T3 /home/tiratatp/Repositories/snia_traces/T3/DisplayAdsPayload/Combined/disk0_1hrs.txt\n",
      "T4 /home/tiratatp/Repositories/snia_traces/T4/Exchange-Server-Traces/Combined/disk8_1hrs.txt\n",
      "T5 /home/tiratatp/Repositories/snia_traces/T5/MSNStorageCFS/Combined/disk6_filtered_1hrs.txt\n",
      "T6 /home/tiratatp/Repositories/snia_traces/T6/MSNStorageFileServer/Combined/disk5_filtered_1hrs.txt\n",
      "T7 /home/tiratatp/Repositories/snia_traces/T7/BuildServer/Combined/disk0_filtered_1hrs.txt\n",
      "T8 /home/tiratatp/Repositories/snia_traces/T8/DevelopmentToolsRelease/Combined/disk6_filtered_1hrs.txt\n",
      "T9 /home/tiratatp/Repositories/snia_traces/T9/RadiusAuthentication/Combined/disk0_filtered_1hrs.txt\n",
      "T10 /home/tiratatp/Repositories/snia_traces/T10/RadiusBackEndSQLServer/Combined/disk4_filtered_1hrs.txt\n"
     ]
    }
   ],
   "source": [
    "#MAIN PROCESSING LOOP\n",
    "# Heavily modified to use pandas\n",
    "for _, trace in traces:\n",
    "    print _, trace\n",
    "        \n",
    "    # read trace into memory\n",
    "    t = pd.read_csv(trace, delimiter=' ', usecols=[0,1,2,3,4], \\\n",
    "                    header=None, names=['offset', 'dskno', 'blkno', 'blkcount', 'flag'], \\\n",
    "                    dtype={'offset':np.str_, 'dskno':np.int_, 'blkno':np.int_, 'blkcount':np.int_, 'flag':np.int_}, \\\n",
    "                    na_filter=False, engine='c')\n",
    "\n",
    "    # 1. First we need to merge sequential IOs\n",
    "    # compare previous IO and tag it if it's sequential\n",
    "    t['is_seq'] = (t['flag'].shift(1) == t['flag']) & ((t['blkno'] + t['blkcount']).shift(1) == t['blkno'])\n",
    "    # use cumsum to help group the IO\n",
    "    t['io_num'] = (~t['is_seq']).astype(int).cumsum()\n",
    "    # merge sequential IO\n",
    "    t = t.groupby(['io_num'], as_index=False).agg({\n",
    "            'offset': 'first',\n",
    "            'dskno': 'first',\n",
    "            'blkno': 'min',\n",
    "            'blkcount': 'sum',\n",
    "            'flag': 'first',\n",
    "        }).reset_index()\n",
    "    \n",
    "    # 2. Set up all the shelters\n",
    "    # find the number of shelter by finding the highest tail\n",
    "    t['tail'] = t['blkno'] + ((t['blkno'] / y) * x) + t['blkcount']\n",
    "    shelter_count = np.floor(t['tail'].max() / y)\n",
    "    \n",
    "    # 3. Add the fifth columns\n",
    "    t['is_shltr'] = ((t['blkcount'] <= policy_size * 2) & (t['flag'] == 0))\n",
    "    \n",
    "    # 4. reorder to the right columns\n",
    "    t = t[['offset', 'dskno', 'blkno', 'blkcount', 'flag', 'is_shltr']]\n",
    "\n",
    "    # full_shelter_search_window\n",
    "    window = 100\n",
    "\n",
    "    #INITIALIZE\n",
    "    #shelters: look up shelter by blk_num\n",
    "    shelters = {}\n",
    "\n",
    "    # initialize all shelters\n",
    "    i=0\n",
    "    while i <= shelter_count:    \n",
    "        shelter_blk = y * i + (x * 9)\n",
    "        shelters[shelter_blk] = Shelter(shelter_blk)\n",
    "        i += 1\n",
    "    tail = -1\n",
    "    current_reqs = None\n",
    "\n",
    "    #remember whether last write was sheltered; \n",
    "    #this affects how we shelter a write when the current tail is inside a shelter\n",
    "    last_sheltered = False\n",
    "    \n",
    "    # generate output files' name\n",
    "    trace_path_comp = path.split(trace)\n",
    "    trace_file_comp = trace_path_comp[1].split('.')\n",
    "    outtrace = path.join(trace_path_comp[0], \"%s_sheltered.txt\" % trace_file_comp[0])\n",
    "    outshelter = path.join(trace_path_comp[0], \"%s_shelter_read.txt\" % trace_file_comp[0])        \n",
    "\n",
    "    with open(outtrace, \"w\") as output:\n",
    "        writer = csv.writer(output, delimiter=' ')\n",
    "        # convert our dataframe into regular list of list so that Nora's code still work\n",
    "        reader = t.values.tolist()\n",
    "        reader = map(lambda x: [x[0], int(x[1]), int(x[2]), int(x[3]), int(x[4]), int(x[5])], reader)\n",
    "        \n",
    "        for row in tqdm(reader):\n",
    "            current_reqs = CurrentReq(row)\n",
    "            if current_reqs.should_shelter():\n",
    "                shelter_writes(current_reqs)\n",
    "                last_sheltered = True\n",
    "            else:\n",
    "                current_reqs.shift_requests()\n",
    "                last_sheltered = False\n",
    "                \n",
    "            #Now that requests have been modified as needed,\n",
    "            #we can write them to outfile\n",
    "            for req in current_reqs.requests:\n",
    "                writer.writerow(req)\n",
    "\n",
    "            #update tail\n",
    "            tail = current_reqs.get_next_blk()\n",
    "        \n",
    "    # Done! Calc some stats\n",
    "    sorted_shelters = sorted(shelters.items(), key=operator.itemgetter(0))\n",
    "    #shelters_by_bcount = map(lambda tup: (tup[0], sum([bcount for _, bcount in tup[1].reqs])), sorted_shelters)    \n",
    "    #print \"total sheltered:\", sum([bcount for _, bcount in shelters_by_bcount])\n",
    "    \n",
    "    with open(outshelter, \"w\") as out:    \n",
    "        for block, shelter in sorted_shelters:\n",
    "            if len(shelter.reqs) == 0:\n",
    "                continue\n",
    "            t = {\n",
    "                \"time\": 0,\n",
    "                \"devno\": 0,\n",
    "                \"blkno\": block,\n",
    "                \"bcount\": sum([bcount for _, bcount in shelter.reqs]),\n",
    "                \"flags\": 1, # read\n",
    "            };\n",
    "            out.write(\"%s %d %d %d %d\\n\" % (\"{0:.3f}\".format(t['time']), t['devno'], t['blkno'], t['bcount'], t['flags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
